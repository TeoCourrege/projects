@article{eshraghian2021training,
  title   = {Training spiking neural networks using lessons from deep learning},
  author  = {Eshraghian, Jason K and Ward, Max and Neftci, Emre and Wang, Xinxin
             and Lenz, Gregor and Dwivedi, Girish and Bennamoun, Mohammed and
             Jeong, Doo Seok and Lu, Wei D},
  journal = {Proceedings of the IEEE},
  volume  = {111},
  number  = {9},
  pages   = {1016--1054},
  year    = {2023}
}

@article{LIAO2023126470,
  title    = {A convolutional spiking neural network with adaptive coding for motor imagery classification},
  journal  = {Neurocomputing},
  volume   = {549},
  pages    = {126470},
  year     = {2023},
  issn     = {0925-2312},
  doi      = {https://doi.org/10.1016/j.neucom.2023.126470},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231223005933},
  author   = {Xiaojian Liao and Yuli Wu and Zi Wang and Deheng Wang and Hongmiao Zhang},
  keywords = {Spiking neural network, Motor imagery, Adaptive coding},
  abstract = {Motor imagery (MI) signal classification is crucial for brain-computer interfaces (BCI). The third-generation neural network, spiking neural network (SNN), has rich neurodynamic properties in the spatiotemporal domain, and therefore it is more suitable for processing EEG signals. However, the feature extraction capability of the SNN previously applied to MI signal classification is limited by its structure, and the modelâ€™s classification accuracy is not comparable to the state-of-the-art algorithms. In this paper, we propose a spiking neural network model called SCNet, which combines the feature extraction capability of CNN with the biological interpretability of SNN, making the model structurally closer to the biological neuronal dynamical system and improving the classification accuracy. SCNet reduces information loss by adaptive coding with learnability and solves the training difficulties of spiking neural networks by surrogate gradient learning. We evaluated the performance of the proposed SCNet on three typically representative motor imagery datasets. The validation shows that the model outperforms state-of-the-art SNN-based MI classification methods and various ANN and machine learning methods. The experimental results demonstrate the generality and effectiveness of the proposed motor imagery EEG signal classification model. Better classification results can be obtained by designing a well-structured spiking neural network.}
}

@article{pfeiffer2018,
  title    = {Deep Learning With Spiking Neurons: Opportunities and Challenges},
  journal  = {frontiers},
  volume   = {12},
  year     = {2018},
  doi      = {https://doi.org/10.3389/fnins.2018.00774},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231223005933},
  author   = {Pfeiffer, Michael and Pfeil, Thomas},
  abstract = {Spiking neural networks (SNNs) are inspired by information processing in biology, where sparse and asynchronous binary signals are communicated and processed in a massively parallel fashion. SNNs on neuromorphic hardware exhibit favorable properties such as low power consumption, fast inference, and event-driven information processing. This makes them interesting candidates for the efficient implementation of deep neural networks, the method of choice for many machine learning tasks. In this review, we address the opportunities that deep spiking networks offer and investigate in detail the challenges associated with training SNNs in a way that makes them competitive with conventional deep learning, but simultaneously allows for efficient mapping to hardware. A wide range of training methods for SNNs is presented, ranging from the conversion of conventional deep networks into SNNs, constrained training before conversion, spiking variants of backpropagation, and biologically motivated variants of STDP.}
}



@article{zhu2023spikegpt,
        title = {SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks},
        author = {Zhu, Rui-Jie and Zhao, Qihang and Li, Guoqi and Eshraghian, Jason K.},
        journal = {arXiv preprint arXiv:2302.13939},
        year    = {2023}
}



@book{gerstner2014neuronal,
  title     = {Neuronal Dynamics: From single neurons to networks and models of cognition},
  author    = {Gerstner, Wulfram and Kistler, Werner M. and Naud, Richard and Paninski, Liam},
  year      = {2014},
  publisher = {Cambridge University Press},
  url       = {https://neuronaldynamics.epfl.ch/index.html}
}


