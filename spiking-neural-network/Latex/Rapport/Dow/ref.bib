@misc{snn_survey,
    author = "Eshraghian, Jason K. and Ward, Max and Neftci, Emre and Wang, Xinxin and Lenz, Gregor and Dwivedi, Girish and Bennamoun, Mohammed and Jeong, Doo Seok and Lu, Wei D.",
    title = "{Training Spiking Neural Networks Using Lessons From Deep Learning}",
    journal = "arXiv preprint",
    year = "2021",
    howpublished={\url{https://arxiv.org/abs/2109.12894}},
    abstract = "The brain is the perfect place to look for inspiration to develop more efficient neural networks. The inner workings of our synapses and neurons provide a glimpse at what the future of deep learning might look like. This paper serves as a tutorial and perspective showing how to apply the lessons learnt from several decades of research in deep learning, gradient descent, backpropagation and neuroscience to biologically plausible spiking neural neural networks. We also explore the delicate interplay between encoding data as spikes and the learning process; the challenges and solutions of applying gradient-based learning to spiking neural networks; the subtle link between temporal backpropagation and spike timing dependent plasticity, and how deep learning might move towards biologically plausible online learning. Some ideas are well accepted and commonly used amongst the neuromorphic engineering community, while others are presented or justified for the first time here. A series of companion interactive tutorials complementary to this paper using our Python package, snnTorch, are also made available.",
}

@misc{codings,
    author = "Guo, Wenzhe and E. Fouda, Mohammed and M. Eltawil, Ahmed and Nabil Salama, Khaled",
    title = "{Neural Coding in Spiking Neural Networks: A Comparative Study for Robust Neuromorphic Systems}",
    journal = "arXiv preprint",
    year = "2021",
    howpublished={\url{https://www.frontiersin.org/articles/10.3389/fnins.2021.638474/full}},
    abstract = "",
}

@misc{model_framework,
    author = "Wu, Jibin and Chua, Yansong and Zhang, Malu and Li, Haizhou and Tan, Kai Chen",
    title = "{A Spiking Neural Network Framework for Robust Sound Classification}",
    journal = "Predatory publishers",
    year = "2019",
    howpublished={\url{https://www.frontiersin.org/articles/10.3389/fnins.2018.00836/full}},
    abstract = "",
}

@misc{firing_comparison,
    author = "Yamazaki, Kashu and Vo-Ho, Viet-Khoa and Bulsara, Darshan and Le, Ngan",
    title = "{Spiking Neural Networks and Their Applications: A Review}",
    journal = "arXiv preprint",
    year = "2021",
    howpublished={\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9313413/}},
    abstract = "",
}

@misc{memristor_synapses,
  author       = {Taeyoon Kim and Suman Hu and Jaewook Kim and Joon Young Kwak and Jongkil Park and Suyoun Lee and Inho Kim and Jong-Keuk and Park YeonJoo Jeong},
  howpublished = {\url{https://www.frontiersin.org/articles/10.3389/fncom.2021.646125/full#B4}},
  title        = {Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update},
  year         = {2021},
  abstract = "Among many artificial neural networks, the research on Spike Neural Network (SNN), which mimics the energy-efficient signal system in the brain, is drawing much attention. Memristor is a promising candidate as a synaptic component for hardware implementation of SNN, but several non-ideal device properties are making it challengeable. In this work, we conducted an SNN simulation by adding a device model with a non-linear weight update to test the impact on SNN performance. We found that SNN has a strong tolerance for the device non-linearity and the network can keep the accuracy high if a device meets one of the two conditions: 1. symmetric LTP and LTD curves and 2. positive non-linearity factors for both LTP and LTD. The reason was analyzed in terms of the balance between network parameters as well as the variability of weight. The results are considered to be a piece of useful prior information for the future implementation of emerging device-based neuromorphic hardware.",
}

@misc{rething_comparison_ann_snn,
    author = "Lei Deng and Yujie Wu and Xing Hu and Ling Liang and Yufei Ding and Guoqi Li and Guangshe Zhao and Peng Li and Yuan Xie",
    title = "{Rethinking the performance comparison between SNNS and ANNS}",
    journal = "ScienceDirect",
    year = "2020",
    howpublished={\url{https://www.sciencedirect.com/science/article/pii/S0893608019302667?ref=pdf_download&fr=RR-2&rr=829f60cc982b9a09}},
    abstract = "Artificial neural networks (ANNs), a popular path towards artificial intelligence, have experienced remarkable success via mature models, various benchmarks, open-source datasets, and powerful computing platforms. Spiking neural networks (SNNs), a category of promising models to mimic the neuronal dynamics of the brain, have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However, for a long time, there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing, SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently, researchers attempt to address this issue by borrowing learning methodologies from ANNs, such as backpropagation, to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size, whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs, the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics.

In this paper, we take the visual recognition task as a case study to answer the questions of “what workloads are ideal for SNNs and how to evaluate SNNs makes sense”. We design a series of contrast tests using different types of datasets (ANN-oriented and SNN-oriented), diverse processing models, signal conversion methods, and learning algorithms. We propose comprehensive metrics on the application accuracy and the cost of memory & compute to evaluate these models, and conduct extensive experiments. We evidence the fact that on ANN-oriented workloads, SNNs fail to beat their ANN counterparts; while on SNN-oriented workloads, SNNs can fully perform better. We further demonstrate that in SNNs there exists a trade-off between the application accuracy and the execution cost, which will be affected by the simulation time window and firing threshold. Based on these abundant analyses, we recommend the most suitable model for each scenario. To the best of our knowledge, this is the first work using systematical comparisons to explicitly reveal that the straightforward workload porting from ANNs to SNNs is unwise although many works are doing so and a comprehensive evaluation indeed matters. Finally, we highlight the urgent need to build a benchmarking framework for SNNs with broader tasks, datasets, and metrics.",
}

@article{advantage_disadvantage,
    author = "Vadapalli, Pavan" ,
    title = "Spiking Neural Network: Everything You Need To Know",
    journal = "",
    year = "2023" 
}